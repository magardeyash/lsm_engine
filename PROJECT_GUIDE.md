# ğŸ” LSM Engine â€” Complete File-by-File Explanation

This is a **Log-Structured Merge Tree (LSM Tree)** storage engine â€” the same architecture used by **RocksDB, LevelDB, and Cassandra**. It's a key-value store optimized for high write throughput by batching writes in memory and flushing them to disk in sorted files.

---

## ğŸ—‚ï¸ Project Structure Overview

```
lsm_engine/
â”œâ”€â”€ include/lsm/       â† Public API (what users of the engine see)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ db/            â† Core engine logic (MemTable, WAL, Versioning, Compaction)
â”‚   â”œâ”€â”€ table/         â† SSTable read/write (on-disk sorted files)
â”‚   â””â”€â”€ util/          â† Low-level primitives (hashing, caching, encoding)
â”œâ”€â”€ tests/             â† Unit tests for every major component
â””â”€â”€ CMakeLists.txt     â† Build system
```

---

## ğŸ“ `include/lsm/` â€” The Public API

These are the **only headers an external user of your engine needs**. Think of them as the contract.

| File | What it does |
|------|-------------|
| `db.h` | **The main interface.** Defines the abstract `DB` class with `Open()`, `Put()`, `Get()`, `Delete()`, `NewIterator()`, and `DestroyDB()`. Users only ever touch this. |
| `options.h` | **Configuration knobs.** `Options` (write buffer size, bloom filter bits, compaction triggers, block size, cache capacity), `ReadOptions` (verify checksums?, fill cache?), `WriteOptions` (fsync WAL before ack?). |
| `slice.h` | **A non-owning string view.** Like `std::string_view` but with a custom compare. Used everywhere instead of copying strings to avoid heap allocations. The core data type for keys and values. |
| `status.h` | **Error handling.** A `Status` object encoding OK/NotFound/Corruption/IOError etc. in a compact `char*` buffer. Every operation returns one. |
| `iterator.h` | **Abstract bidirectional cursor.** `Seek`, `Next`, `Prev`, `key()`, `value()`. Implemented by MemTable, SSTable, merge iterators. |
| `comparator.h` | **Ordering contract.** Abstract class with `Compare()`, `FindShortestSeparator()`, `FindShortSuccessor()`. Used to sort keys. Default is byte-lexicographic. |

---

## ğŸ“ `src/db/` â€” The Core Engine

This is the **brain** of the LSM tree.

### `db_impl.h` / `db_impl.cc` â€” **The Main Implementation**
`DBImpl` is the concrete class that implements the abstract `DB` interface.

**Key responsibilities:**
- **`Open()`** â†’ Creates WAL, recovers from crash, initializes MemTable & VersionSet
- **`Put()` / `Delete()`** â†’ Calls `Write()`, which appends to WAL then inserts into MemTable
- **`Get()`** â†’ Checks MemTable first â†’ then immutable MemTable â†’ then each SSTable level via VersionSet (newest-first)
- **`MakeRoomForWrite()`** â†’ When MemTable is full, rotates it to `imm_` (immutable) and signals the background thread to flush it
- **Group Commit (`BuildBatchGroup`)** â†’ Multiple concurrent writers are batched into one WAL write for efficiency
- **Background thread** â†’ Runs `BackgroundCall()` which either flushes `imm_` to L0 SSTable or runs compaction

**Key members:**
- `mem_` â€” the active, mutable MemTable
- `imm_` â€” the immutable MemTable being flushed to disk
- `log_` â€” the WAL writer
- `versions_` â€” manages all SSTable file metadata
- `table_cache_` â€” LRU cache of open SSTable file handles

---

### `skiplist.h` â€” **The MemTable's Data Structure**
A **lock-free probabilistic sorted data structure** (header-only template).

- `Insert(key)` â€” O(log n) random insertion
- `Contains(key)` â€” O(log n) lookup
- `Iterator` â€” sequential scan in sorted order
- Uses `std::atomic` for its forward pointers â†’ readers need no lock, writers use external mutex
- Max height = 12 levels, branching factor = 4

> **Why SkipList over Red-Black Tree?** Concurrent reads without locking, cache-friendlier traversal, no rebalancing.

---

### `memtable.h` / `memtable.cc` â€” **In-Memory Write Buffer**
Wraps the SkipList to store **internal keys** (user key + sequence number + value type).

- **`Add(seq, type, key, value)`** â†’ encodes as internal key, inserts into skip list
- **`Get(LookupKey, value, status)`** â†’ finds latest version of a key (sequence number descending), handles tombstones
- **`Ref()` / `Unref()`** â†’ reference counting for safe shared access
- **`ApproximateMemoryUsage()`** â†’ triggers flush when it exceeds `write_buffer_size`

**Internal key format:** `[user_key bytes][7 bytes seq num][1 byte type]`
- `type = 0x1` â†’ value present
- `type = 0x0` â†’ deletion tombstone

---

### `wal.h` / `wal.cc` â€” **Write-Ahead Log (Crash Recovery)**
Physical log written to disk *before* every write.

**Record format:** `[CRC32: 4 bytes][Length: 2 bytes][Type: 1 byte][Data: N bytes]`

- **`WalWriter::AddRecord(slice)`** â†’ appends a record to the log file. Calls `Sync()` if `WriteOptions::sync == true` (fsync to disk)
- **`WalReader::ReadRecord()`** â†’ reads records back sequentially during recovery, validates CRC32, reports corruption
- On restart, `Recover()` replays unprocessed WAL records back into a fresh MemTable

> **Interview point:** WAL guarantees durability. Without it, a crash after MemTable write but before SSTable flush loses data.

---

### `version_edit.h` / `version_edit.cc` â€” **SSTable Change Log (Delta)**
A `VersionEdit` is a **diff** describing changes to the set of SSTable files.

- **`AddFile(level, file_number, size, smallest, largest)`** â†’ records a new SSTable added
- **`DeleteFile(level, file_number)`** â†’ records an SSTable removed by compaction
- **`EncodeTo(string*)`** / **`DecodeFrom(Slice)`** â†’ serialized with varints and written to the MANIFEST file
- `FileMetaData` â€” metadata for one SSTable: file number, size, key range (smallest/largest `InternalKey`), reference count, allowed seeks before compaction

---

### `version_set.h` / `version_set.cc` â€” **The Version Manager (MANIFEST)**
Tracks the complete set of SSTables across all 7 levels at any given point in time.

- **`Version`** â€” a snapshot of all SSTable files at a moment. Linked list of versions.
  - `Get()` â†’ searches files at each level for a key (L0 searches all files, L1+ uses binary search on key ranges)
  - `AddIterators()` â†’ exposes iterators for all files at all levels (used for range scans)
- **`VersionSet`** â€” manages the linked list of `Version`s
  - `LogAndApply(edit)` â†’ applies a `VersionEdit`, creates a new `Version`, writes it to the MANIFEST, installs it as current
  - `Recover()` â†’ reads MANIFEST on startup to reconstruct the current file set
  - `PickCompaction()` â†’ selects which level and files to compact next (score-based)
  - `Finalize()` â†’ computes a compaction score for each version (triggers compaction)

> **MANIFEST file** = a WAL of `VersionEdit`s â€” lets you recover the exact set of live SSTables after a crash.

---

### `compaction.h` / `compaction.cc` â€” **The Compaction Job Descriptor**
A `Compaction` object describes *one* compaction job picked by `VersionSet::PickCompaction()`.

- `level_` â€” which level is being compacted
- `inputs_[0]` â€” files FROM the source level
- `inputs_[1]` â€” overlapping files FROM the next level
- `grandparents_` â€” files in level+2 used to limit output file size
- `IsTrivialMove()` â€” true if input[1] is empty â†’ file just moves down a level, no merge needed
- `IsBaseLevelForKey()` â€” checks if a key exists in deeper levels (to decide if a tombstone can be dropped)
- `ShouldStopBefore()` â€” limits output file size to avoid too much overlap with grandparent level

The actual compaction work (merging + writing) happens in `DBImpl::DoCompactionWork()`.

---

### `merger.h` / `merger.cc` â€” **N-Way Merge Iterator**
Merges N sorted iterators (from MemTable + multiple SSTable levels) into a single sorted stream.

- `NewMergingIterator(comparator, children, n)` â†’ returns a single iterator that yields keys in globally sorted order by always picking the smallest key across all child iterators
- Used during compaction (to merge input files) and during full iteration (`NewIterator`)

---

## ğŸ“ `src/table/` â€” SSTable Files (On-Disk Sorted Storage)

### `format.h` / `format.cc` â€” **SSTable Binary Format**
Defines the on-disk layout of every SSTable file.

**SSTable structure:**
```
[Data Block 0]
[Data Block 1]
...
[Data Block N]
[Meta Block: bloom filter]
[Metaindex Block]    â† maps meta block names â†’ BlockHandles
[Index Block]        â† maps last_key_in_block â†’ BlockHandle (for binary search)
[Footer: 48 bytes]   â† BlockHandle to index + metaindex, 8-byte magic
```

- **`BlockHandle`** â€” an `(offset, size)` pair pointing to any block in the file
- **`Footer`** â€” the fixed-size tail of every SSTable, read first. Contains handles to the index and metaindex blocks
- **`BlockBuilder`** â€” builds a single data block. Keys are prefix-compressed (delta-encoded). Every `block_restart_interval` entries, a full key is stored as a restart point for binary search

---

### `sstable_builder.h` / `sstable_builder.cc` â€” **Writing SSTables**
`TableBuilder` writes a new SSTable file sequentially (keys must be added in sorted order).

- `Add(key, value)` â†’ adds a key-value pair, flushing the current data block when it exceeds `block_size`
- `Flush()` â†’ finalizes the current data block, writes it to disk, adds an entry to the index block
- `Finish()` â†’ writes bloom filter block, metaindex block, index block, then footer
- `Abandon()` â†’ call if you don't want to finish (e.g., on error)
- Uses `BlockBuilder` internally for delta-compressed key encoding

---

### `sstable_reader.h` / `sstable_reader.cc` â€” **Reading SSTables**
`Table` opens and reads an existing SSTable file.

- `Open(options, filename, size, &table)` â†’ reads the footer, then index block, then bloom filter metadata into memory
- `NewIterator()` â†’ a **Two-Level Iterator**: outer iterator walks the index block to find a data block handle, then opens that data block and scans entries
- `MayContain(user_key)` â†’ queries the bloom filter â€” avoids reading a data block if the key is definitely absent
- `InternalGet()` â†’ used by `TableCache::Get()` â€” binary searches index, reads one data block, finds exact key
- `ApproximateOffsetOf()` â†’ used for estimating compaction output sizes

---

### `table_cache.h` / `table_cache.cc` â€” **LRU Cache for Open SSTable Files**
Avoids repeatedly opening and closing SSTable file handles.

- `NewIterator(file_number, file_size)` â†’ looks up the file in the LRU cache; if absent, opens it and caches the `Table*`
- `Get(file_number, file_size, key, ...)` â†’ cache lookup + `InternalGet()` on the table
- `MayContain(file_number, file_size, key)` â†’ bloom filter check through the cache
- `Evict(file_number)` â†’ called after a file is deleted by compaction to remove it from the cache

---

## ğŸ“ `src/util/` â€” Low-Level Utilities

| File | What it does |
|------|-------------|
| `coding.h/.cc` | **Binary serialization.** Fixed-width (`EncodeFixed32/64`) and variable-length (`PutVarint32/64`) integer encoders. Little-endian. Used for SSTable binary format and WAL records. |
| `crc32.h/.cc` | **CRC32 checksum.** Used to detect corruption in WAL records and SSTable blocks. |
| `hash.h/.cc` | **MurmurHash** variant used by the Bloom filter to hash keys. |
| `bloom.h/.cc` | **Bloom Filter.** Probabilistic set membership test. `CreateFilter(keys, n)` â†’ builds bit array. `KeyMayMatch(key, filter)` â†’ returns false if definitely absent, true if probably present. Reduces disk I/O on point lookups. |
| `cache.h/.cc` | **LRU Cache.** Thread-safe, shard-locked LRU cache. Abstract `Cache` interface + `NewLRUCache(capacity)`. Used by `TableCache`. Handles are reference-counted. |
| `comparator.cc` | Implements the default `BytewiseComparatorImpl` (lexicographic byte comparison). Also implements `FindShortestSeparator` (shorten SSTable index entries) and `FindShortSuccessor` (used for last entry in index block). |
| `options.cc` | Constructs the default `Options` (sets `comparator` to bytewise). |
| `status.cc` | Implements `Status::ToString()` and copy operations. State stored as `[4-byte len][1-byte code][message]`. |

---

## ğŸ“ `tests/` â€” Unit Tests

| Test File | What it tests |
|-----------|--------------|
| `test_db.cc` | End-to-end: `Open`, `Put`, `Get`, `Delete`, reopen persistence |
| `test_memtable.cc` | MemTable insert, lookup, tombstones, sequence numbers |
| `test_sstable.cc` | `TableBuilder` write + `Table::Open` read, key lookup |
| `test_bloom.cc` | False positive rate, no false negatives |
| `test_compaction.cc` | L0â†’L1 compaction, key merging, tombstone dropping |
| `test_concurrency.cc` | Multi-threaded reads and writes, writer group commit |
| `test_crash_recovery.cc` | WAL replay after simulated crash |
| `test_group_commit.cc` | Multiple writers batched into single WAL record |
| `test_bench.cc` | Throughput benchmark for sequential and random writes |

---

## ğŸ”„ The Complete Write Flow (Interview Ready)

```
Put("key", "value")
  â”‚
  â–¼
DBImpl::Put() â†’ DBImpl::Write()
  â”‚
  â”œâ”€ 1. Acquire mutex
  â”œâ”€ 2. BuildBatchGroup() â† coalesce concurrent writers
  â”œâ”€ 3. WalWriter::AddRecord() â† write to WAL on disk
  â”œâ”€ 4. MemTable::Add() â† insert into skip list
  â”œâ”€ 5. MakeRoomForWrite() â† if MemTable full:
  â”‚       â”œâ”€ rotate mem_ â†’ imm_
  â”‚       â”œâ”€ create new MemTable + new WAL file
  â”‚       â””â”€ signal background thread
  â””â”€ 6. Return OK to all batched writers
```

## ğŸ”„ The Complete Read Flow

```
Get("key")
  â”‚
  â”œâ”€ 1. Check mem_ (active MemTable, skip list lookup)
  â”œâ”€ 2. Check imm_ (immutable MemTable, if exists)
  â”œâ”€ 3. Check current Version (VersionSet)
  â”‚       â”œâ”€ L0: search ALL files (overlap possible) â†’ newest first
  â”‚       â”œâ”€ L1: binary search by key range â†’ at most 1 file
  â”‚       â”œâ”€ L2..L6: same binary search
  â”‚       â””â”€ Each file: TableCache lookup â†’ Bloom filter check â†’ Index binary search â†’ Block read
  â””â”€ 4. Return value or NotFound
```

## ğŸ”„ The Background Compaction Flow

```
BackgroundCall()
  â”‚
  â”œâ”€ If imm_ exists:
  â”‚     WriteLevel0Table() â†’ TableBuilder writes sorted SSTable
  â”‚                         â†’ VersionEdit records new L0 file
  â”‚                         â†’ LogAndApply() installs new Version
  â”‚
  â””â”€ Else:
        PickCompaction() â†’ selects files from level N + level N+1
        DoCompactionWork():
          â”œâ”€ MergingIterator over all input files
          â”œâ”€ For each key (newest sequence wins):
          â”‚     Skip older duplicates
          â”‚     Drop tombstones at bottom level
          â”‚     Write survivors to new SSTable(s)
          â””â”€ LogAndApply() â†’ deletes old files, adds new files as atomic version change
```

---

## ğŸ¯ Key Concepts for Interviews

| Concept | Your Implementation |
|---------|-------------------|
| **Write path** | WAL â†’ MemTable (SkipList) â†’ SSTable (on flush) |
| **Read path** | MemTable â†’ imm â†’ L0 (all) â†’ L1+ (binary search) |
| **Why WAL?** | Crash recovery â€” replay log to rebuild lost MemTable |
| **Why SkipList?** | Lock-free concurrent reads, O(log n) writes |
| **Why Bloom filters?** | Skip disk I/O for definitely-absent keys |
| **Why compaction?** | Merge duplicate keys, drop tombstones, bound read amplification |
| **Version/MANIFEST** | Atomic metadata changes â€” consistent view even during compaction |
| **Group commit** | Batch N concurrent `Put()` calls into 1 WAL write = higher throughput |
| **Block cache** | LRU cache of decompressed 4KB data blocks â€” reduces disk reads |
| **Sequence numbers** | MVCC-lite â€” each write gets a monotonically increasing seq num; reads see consistent snapshots |
